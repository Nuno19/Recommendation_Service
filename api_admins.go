/*
 * Recommendation API
 *
 * This is a recommendation API using k-means Clustering
 *
 * API version: 1.0.0
 * Contact: capela.nuno@ua.com
 * Generated by: Swagger Codegen (https://github.com/swagger-api/swagger-codegen.git)
 */

package main

import (
	"encoding/json"
	"fmt"
	"math"
	"math/rand"
	"net/http"
	"os"
	"regexp"
	"strconv"
	"strings"

	kmeans "github.com/Nuno19/KMeans-Go"
	tfidf "github.com/Nuno19/TF_IDF-Go"
	"github.com/reiver/go-porterstemmer"
)

var kmean kmeans.KMeans = kmeans.KMeans{K: 20, MaxIter: 100}

var tf_idf tfidf.TF_IDF = tfidf.TF_IDF{}
var lastIdx int
var cList []string
var stopWords = tfidf.WordSet{"the", "a", "and", "you", "your", "he", "she", "his", "her", "of", "at", "\\N"}
var types []string

func check(e error) {
	if e != nil {
		panic(e)
	}

}
func treatSentence(sentence string) tfidf.WordSet {
	set := tfidf.WordSet{}
	for _, word := range strings.Split(sentence, " ") {
		word = treatWord(word)
		if !stopWords.Exists(word) && word != "" && len(word) > 3 {
			set = append(set, word)
		}
	}
	return set
}

func treatWord(word string) string {
	word = porterstemmer.StemString(word)

	var re = regexp.MustCompile(`(tt\d{7}\/\d{4}(-\d)?|(ch|co|ev|nm|tt)\d{7})`)
	word = re.ReplaceAllString(word, "")
	reg := regexp.MustCompile("[^A-Za-zÀ-ÿ]+")
	word = reg.ReplaceAllString(word, "")
	word = strings.ToLower(word)

	return strings.ReplaceAll(word, "\"", "")
}

func clearItems(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Content-Type", "application/json; charset=UTF-8")
	types = []string{}
	cList = []string{}
}

//LoadItem - Loads data into the dataset
func LoadItem(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Content-Type", "application/json; charset=UTF-8")

	corpus := r.FormValue("itemList")

	list := strings.Split(corpus, "\n")

	types = strings.Split(list[0], "\t")
	list = list[1:]

	cList = append(cList, list...)

	corpusSet := make([]tfidf.WordSet, len(list))
	for i, l := range list {
		if l != "" {
			l = strings.ReplaceAll(l, "\t", " ")
		}
		corpusSet[i] = treatSentence(l)
	}

	tf_idf.AddToWordSet(corpusSet)
	fmt.Printf("WORD  SET LENGTH : %d\n", len(tf_idf.SetWord))
	tf_idf.SortMap()

	for _, val := range corpusSet {
		tf_idf.SetCount(val)
		tf_idf.ComputeTF(val)
	}
	//fmt.Println(corpusSet[0])
	//fmt.Println(tf_idf.WordCountList[0])

	tf_idf.ComputeIDF()

	tf_idf.ComputeTFIDF()

	js, _ := json.Marshal(map[string]string{"Status": "Success", "SET SIZE": fmt.Sprint(len(tf_idf.SetWord))})

	w.WriteHeader(http.StatusOK)
	w.Write(js)

}

//LoadItemList - Reffit Data into new clusters
func LoadItemList(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Content-Type", "application/json; charset=UTF-8")
	w.WriteHeader(http.StatusOK)

	Kerr := math.MaxFloat64
	labels := make([]int, len(kmean.Points))
	k := kmean.K
	finalK := kmean.K
	for j := 0; j < 4; j++ {
		for i := 0; i < 3; i++ {
			kmean.K = k + j
			fitted := kmean.Fit(tf_idf.GetAllPointsTFIDF())
			if !fitted {
				continue
			}
			sse := kmean.ComputeSSE()
			if sse < Kerr {
				finalK = kmean.K
				labels = kmean.Labels
				Kerr = sse
				fmt.Printf("LabelCount: %s ERROR: %f\n", fmt.Sprint(kmeans.LabelCount(labels, kmean.K)), Kerr)
			}
		}
	}
	kmean.K = finalK
	dir, err := os.Create("files/")
	defer dir.Close()
	dir.Sync()

	s := "files/Items.txt"

	f, err := os.Create(s)
	check(err)

	for i, l := range cList {
		vals := strings.Split(l, "\t")
		m := map[string]string{}

		for j, lab := range types {
			m[lab] = vals[j]
		}

		js, err := json.Marshal(m)
		check(err)

		t, err := json.Marshal(Item{Id: strconv.FormatInt(int64(i), 10), Data: string(js), BelongsTo: labels[i]})
		check(err)

		f.Write(t)
		f.WriteString("\n")

		f.Sync()
	}

	f.Close()

	js, _ := json.Marshal(map[string]string{"Status": "Success", "SSE": fmt.Sprintf("%f", Kerr), "LabelCounts": fmt.Sprint(kmeans.LabelCount(labels, kmean.K)), "K": fmt.Sprintf("%d", kmean.K)})

	w.WriteHeader(http.StatusOK)
	w.Write(js)

}

//SetClusterCount - Set Cluster Count Endpoint
func SetClusterCount(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Content-Type", "application/json; charset=UTF-8")

	data := r.FormValue("k")
	val, err := strconv.Atoi(data)
	if err != nil {
		http.Error(w, "Invalid k value!", http.StatusInternalServerError)
		return
	}
	kmean.K = val
	w.WriteHeader(http.StatusOK)

	ret, _ := json.Marshal(map[string]string{"k": strconv.Itoa(kmean.K), "Status": "Success"})
	w.Write(ret)
}

//GetTextRecommended - Set Cluster Count Endpoint
func GetTextRecommended(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Content-Type", "application/json; charset=UTF-8")

	fmt.Printf("LEN TF_IDF: %d | LEN clist: %d | LEN TF: %d\n", len(tf_idf.TfIdf), len(cList), len(tf_idf.Tf))
	data := r.FormValue("query")
	set := []tfidf.WordSet{treatSentence(data)}
	tf_idf.AddToWordSet(set)
	tf_idf.SortMap()
	tf_idf.SetCountIdx(set[0], len(cList))
	tf_idf.ComputeTFIdx(set[0], len(cList))

	tf_idf.ComputeIDF()
	tf_idf.ComputeTFIDF()

	kmean.Fit(tf_idf.GetAllPointsTFIDF()[:len(tf_idf.TfIdf)-1])

	fmt.Println("After Fit")
	fmt.Printf("LEN TF_IDF: %d | LEN clist: %d | LEN TF: %d\n", len(tf_idf.TfIdf), len(cList), len(tf_idf.Tf))
	fmt.Println(kmean.LabelCount())
	sse := kmean.ComputeSSE()
	fmt.Println(sse)
	centIdx := kmean.ComputeClosestCentroidIdx(tf_idf.GetPointByIndexTFIDF(len(tf_idf.TfIdf) - 1))
	fmt.Println(centIdx)

	kNearest := Items{}
	for _, i := range rand.Perm(len(cList)) {
		vals := strings.Split(cList[i], "\t")
		m := map[string]string{}

		for j, lab := range types {
			m[lab] = vals[j]
		}

		js, err := json.Marshal(m)
		check(err)
		if kmean.Labels[i] == centIdx {
			kNearest = append(kNearest, Item{Id: strconv.Itoa(i), Data: string(js)})
		}
		check(err)

	}
	l, _ := json.Marshal(kNearest)
	w.Write(l)
	w.WriteHeader(http.StatusOK)

}
